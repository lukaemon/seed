{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from evaluation.template_list import template_list\n",
    "\n",
    "import utils\n",
    "from utils import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset_cutoff = 200\n",
    "# checkpoints = ['bigscience/T0_3B', 'bigscience/T0', 'bigscience/T0pp', 'google/flan-t5-xl', 'google/flan-t5-xxl']\n",
    "checkpoints = ['bigscience/T0']\n",
    "\n",
    "today = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "output_dir = f'./evaluation_result/{today}'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for checkpoint in checkpoints:\n",
    "    t2t = utils.build_t2t(checkpoint)\n",
    "    results = []\n",
    "\n",
    "    for (dataset_name, subset_name), prompts in template_list.items():\n",
    "        raw_dataset = utils.load_raw_dataset(dataset_name, subset_name)\n",
    "\n",
    "        for prompt_name in prompts:\n",
    "            prompt = utils.get_prompt(dataset_name, subset_name, prompt_name)\n",
    "\n",
    "            input_text, target_text = utils.preprocess_dataset(\n",
    "                raw_dataset, prompt, cutoff=dataset_cutoff\n",
    "            )\n",
    "            test_size = len(input_text)\n",
    "\n",
    "            accuracy, t_lapse, failed_cases = utils.eval(\n",
    "                t2t, input_text, target_text, batch_size=batch_size\n",
    "            )\n",
    "\n",
    "            logger.info(\n",
    "                f\"{checkpoint}: {dataset_name}/{subset_name} - {prompt_name}: {accuracy}\"\n",
    "            )\n",
    "\n",
    "            result = utils.Result(\n",
    "                checkpoint,\n",
    "                dataset_name,\n",
    "                subset_name,\n",
    "                test_size,\n",
    "                t_lapse,\n",
    "                prompt_name,\n",
    "                accuracy,\n",
    "            )\n",
    "            results.append(result)\n",
    "\n",
    "            utils.dump_failed_cases_as_json(\n",
    "                failed_cases,\n",
    "                checkpoint,\n",
    "                dataset_name,\n",
    "                subset_name,\n",
    "                prompt_name,\n",
    "                output_dir,\n",
    "            )\n",
    "\n",
    "    utils.dump_result_as_csv(results, checkpoint, output_dir)\n",
    "\n",
    "    del t2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
