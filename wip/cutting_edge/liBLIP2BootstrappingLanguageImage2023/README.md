## tl;dr

## Context
Coming from [mm-cot](https://github.com/lukaemon/seed/tree/main/paper/zhangMultimodalChainofThoughtReasoning2023). I want to dig deeper into multimodal research. Interested in adaptor architecture with frozen vision encoder and LM. BLIP2 is cutting edge and perfect fit. However, this project involves pretraining, finetuning, serious model surgery, objective function engineering. Pretty sure it's out of my league.

The plan is starting from evaluation, get hands dirty, recognize what's missing, build a plan to bridge the gap and get this done step by step. Expecting 1 at least one month to catch up. 

I see many possible follow ups. It could be a good testbed to unlock future multimodal research.

## Done

## Learned

## Next?

## Log