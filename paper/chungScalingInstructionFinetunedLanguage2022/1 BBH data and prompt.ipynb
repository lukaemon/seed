{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import data_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbh = data_process.BBH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boolean_expressions',\n",
       " 'causal_judgement',\n",
       " 'date_understanding',\n",
       " 'disambiguation_qa',\n",
       " 'dyck_languages',\n",
       " 'formal_fallacies',\n",
       " 'geometric_shapes',\n",
       " 'hyperbaton',\n",
       " 'logical_deduction_five_objects',\n",
       " 'logical_deduction_seven_objects',\n",
       " 'logical_deduction_three_objects',\n",
       " 'movie_recommendation',\n",
       " 'multistep_arithmetic_two',\n",
       " 'navigate',\n",
       " 'object_counting',\n",
       " 'penguins_in_a_table',\n",
       " 'reasoning_about_colored_objects',\n",
       " 'ruin_names',\n",
       " 'salient_translation_error_detection',\n",
       " 'snarks',\n",
       " 'sports_understanding',\n",
       " 'temporal_sequences',\n",
       " 'tracking_shuffled_objects_five_objects',\n",
       " 'tracking_shuffled_objects_seven_objects',\n",
       " 'tracking_shuffled_objects_three_objects',\n",
       " 'web_of_lies',\n",
       " 'word_sorting']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbh.task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbh.n_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boolean_expressions: Evaluate the result of a random Boolean expression. \n",
      "\n",
      "causal_judgement: Answer questions about causal attribution. \n",
      "\n",
      "date_understanding: Infer the date from context. \n",
      "\n",
      "disambiguation_qa: Clarify the meaning of sentences with ambiguous pronouns. \n",
      "\n",
      "dyck_languages: Correctly close a Dyck-n word. \n",
      "\n",
      "formal_fallacies: Distinguish deductively valid arguments from formal fallacies. \n",
      "\n",
      "geometric_shapes: Name geometric shapes from their SVG paths. \n",
      "\n",
      "hyperbaton: Order adjectives correctly in English sentences. \n",
      "\n",
      "logical_deduction_five_objects: A logical deduction task which requires deducing the order of a sequence of objects. \n",
      "\n",
      "logical_deduction_seven_objects: A logical deduction task which requires deducing the order of a sequence of objects. \n",
      "\n",
      "logical_deduction_three_objects: A logical deduction task which requires deducing the order of a sequence of objects. \n",
      "\n",
      "movie_recommendation: Recommend movies similar to the given list of movies. \n",
      "\n",
      "multistep_arithmetic_two: Solve multi-step arithmetic problems. \n",
      "\n",
      "navigate: Given a series of navigation instructions, determine whether one would end up back at the starting point. \n",
      "\n",
      "object_counting: Questions that involve enumerating objects and asking the model to count them. \n",
      "\n",
      "penguins_in_a_table: Answer questions about a table of penguins and their attributes. \n",
      "\n",
      "reasoning_about_colored_objects: Answer extremely simple questions about the colors of objects on a surface. \n",
      "\n",
      "ruin_names: Select the humorous edit that 'ruins' the input movie or musical artist name. \n",
      "\n",
      "salient_translation_error_detection: Detect the type of error in an English translation of a German source sentence. \n",
      "\n",
      "snarks: Determine which of two sentences is sarcastic. \n",
      "\n",
      "sports_understanding: Determine whether an artificially constructed sentence relating to sports is plausible or not. \n",
      "\n",
      "temporal_sequences: Task description: Answer questions about which times certain events could have occurred. \n",
      "\n",
      "tracking_shuffled_objects_five_objects: A task requiring determining the final positions of a set of objects given their initial positions and a description of a sequence of swaps. \n",
      "\n",
      "tracking_shuffled_objects_seven_objects: A task requiring determining the final positions of a set of objects given their initial positions and a description of a sequence of swaps. \n",
      "\n",
      "tracking_shuffled_objects_three_objects: A task requiring determining the final positions of a set of objects given their initial positions and a description of a sequence of swaps. \n",
      "\n",
      "web_of_lies: Evaluate a random boolean function expressed as a word problem. \n",
      "\n",
      "word_sorting: Sort a list of words. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for task in bbh.task_list:\n",
    "    print(f\"{task}: {bbh.instruction(task)}\", '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'date_understanding'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = bbh.task_list[2]\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bbh.instances(task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one week ago from today in MM/DD/YYYY?\\nOptions:\\n(A) 07/09/1972\\n(B) 12/01/1972\\n(C) 07/01/2008\\n(D) 05/13/1972\\n(E) 07/01/1972\\n(F) 08/12/1972',\n",
       " 'target': '(E)'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance = bbh.instances(task)[0]\n",
    "instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Infer the date from context.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = bbh.instruction(task)\n",
    "instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Today is Christmas Eve of 1937. What is the date 10 days ago in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 12/14/2026\n",
      "(B) 12/14/1950\n",
      "(C) 12/14/2007\n",
      "(D) 12/14/1937\n",
      "(E) 07/14/1938\n",
      "(F) 12/14/1988\n",
      "A: Let's think step by step.\n",
      "If today is Christmas Eve of 1937, then today's date is December 24, 1937. 10 days before today is December 14, 1937, that is 12/14/1937. So the answer is (D).\n",
      "\n",
      "Q: Tomorrow is 11/12/2019. What is the date one year ago from today in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 09/04/2018\n",
      "(B) 11/11/2018\n",
      "(C) 08/25/2018\n",
      "(D) 11/02/2018\n",
      "(E) 11/04/2018\n",
      "A: Let's think step by step.\n",
      "If tomorrow is 11/12/2019, then today is 11/11/2019. The date one year ago from today is 11/11/2018. So the answer is (B).\n",
      "\n",
      "Q: Jane and John married on Jan 2, 1958. It is their 5-year anniversary today. What is the date tomorrow in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 01/11/1961\n",
      "(B) 01/03/1963\n",
      "(C) 01/18/1961\n",
      "(D) 10/14/1960\n",
      "(E) 01/03/1982\n",
      "(F) 12/03/1960\n",
      "A: Let's think step by step.\n",
      "If Jane and John married on Jan 2, 1958, then and if it is their 5-year anniversary today, then today's date is Jan 2, 1963. The date tomorrow is Jan 3, 1963, that is 01/03/1963. So the answer is (B).\n"
     ]
    }
   ],
   "source": [
    "cot = bbh.cot(task)\n",
    "print(cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'Today is Christmas Eve of 1937. What is the date tomorrow in MM/DD/YYYY?\\nOptions:\\n(A) 12/11/1937\\n(B) 12/25/1937\\n(C) 01/04/1938\\n(D) 12/04/1937\\n(E) 12/25/2006\\n(F) 07/25/1937',\n",
       "  'target': '(B)'},\n",
       " {'input': 'In the UK, people usually put the day before the month when formatting the date. Therefore, today is 02/01/1987 to them. What is the date a month ago in MM/DD/YYYY?\\nOptions:\\n(A) 12/02/1986\\n(B) 12/01/1986\\n(C) 03/02/1986\\n(D) 12/02/2032\\n(E) 12/02/2062\\n(F) 02/06/1987',\n",
       "  'target': '(A)'},\n",
       " {'input': 'Jane and John married on Jan 2, 1958. It is their 5-year anniversary today. What is the date one week from today in MM/DD/YYYY?\\nOptions:\\n(A) 01/16/1961\\n(B) 01/09/1961\\n(C) 01/09/1963\\n(D) 03/09/1960\\n(E) 07/09/1960\\n(F) 02/28/1961',\n",
       "  'target': '(B)'}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot = bbh.few_shot(task)\n",
    "few_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infer the date from context.\n",
      "\n",
      "Q: Today is Christmas Eve of 1937. What is the date tomorrow in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 12/11/1937\n",
      "(B) 12/25/1937\n",
      "(C) 01/04/1938\n",
      "(D) 12/04/1937\n",
      "(E) 12/25/2006\n",
      "(F) 07/25/1937\n",
      "A: (B)\n",
      "\n",
      "Q: In the UK, people usually put the day before the month when formatting the date. Therefore, today is 02/01/1987 to them. What is the date a month ago in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 12/02/1986\n",
      "(B) 12/01/1986\n",
      "(C) 03/02/1986\n",
      "(D) 12/02/2032\n",
      "(E) 12/02/2062\n",
      "(F) 02/06/1987\n",
      "A: (A)\n",
      "\n",
      "Q: Jane and John married on Jan 2, 1958. It is their 5-year anniversary today. What is the date one week from today in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 01/16/1961\n",
      "(B) 01/09/1961\n",
      "(C) 01/09/1963\n",
      "(D) 03/09/1960\n",
      "(E) 07/09/1960\n",
      "(F) 02/28/1961\n",
      "A: (B)\n",
      "\n",
      "Q: Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one week ago from today in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 07/09/1972\n",
      "(B) 12/01/1972\n",
      "(C) 07/01/2008\n",
      "(D) 05/13/1972\n",
      "(E) 07/01/1972\n",
      "(F) 08/12/1972\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "answer_only = bbh.prompted_instances(task)\n",
    "print(answer_only[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infer the date from context.\n",
      "\n",
      "Q: Today is Christmas Eve of 1937. What is the date 10 days ago in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 12/14/2026\n",
      "(B) 12/14/1950\n",
      "(C) 12/14/2007\n",
      "(D) 12/14/1937\n",
      "(E) 07/14/1938\n",
      "(F) 12/14/1988\n",
      "A: Let's think step by step.\n",
      "If today is Christmas Eve of 1937, then today's date is December 24, 1937. 10 days before today is December 14, 1937, that is 12/14/1937. So the answer is (D).\n",
      "\n",
      "Q: Tomorrow is 11/12/2019. What is the date one year ago from today in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 09/04/2018\n",
      "(B) 11/11/2018\n",
      "(C) 08/25/2018\n",
      "(D) 11/02/2018\n",
      "(E) 11/04/2018\n",
      "A: Let's think step by step.\n",
      "If tomorrow is 11/12/2019, then today is 11/11/2019. The date one year ago from today is 11/11/2018. So the answer is (B).\n",
      "\n",
      "Q: Jane and John married on Jan 2, 1958. It is their 5-year anniversary today. What is the date tomorrow in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 01/11/1961\n",
      "(B) 01/03/1963\n",
      "(C) 01/18/1961\n",
      "(D) 10/14/1960\n",
      "(E) 01/03/1982\n",
      "(F) 12/03/1960\n",
      "A: Let's think step by step.\n",
      "If Jane and John married on Jan 2, 1958, then and if it is their 5-year anniversary today, then today's date is Jan 2, 1963. The date tomorrow is Jan 3, 1963, that is 01/03/1963. So the answer is (B).\n",
      "\n",
      "Q: Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one week ago from today in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 07/09/1972\n",
      "(B) 12/01/1972\n",
      "(C) 07/01/2008\n",
      "(D) 05/13/1972\n",
      "(E) 07/01/1972\n",
      "(F) 08/12/1972\n",
      "A: Let's think step by step.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cot_prompted = bbh.prompted_instances(task, cot=True)\n",
    "print(cot_prompted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(E)\n"
     ]
    }
   ],
   "source": [
    "target = bbh.target(task)\n",
    "print(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cot=False: mean=465.29, min=84, max=1643\n",
      "cot=True: mean=945.07, min=241, max=1971\n"
     ]
    }
   ],
   "source": [
    "# count number of tokens to decide tokenization padding and max length\n",
    "for cot in [False, True]:\n",
    "    all_n_tokens = []\n",
    "\n",
    "    for task in bbh.task_list:\n",
    "        prompts = bbh.prompted_instances(task, cot=cot)\n",
    "        tokenized_prompts = tokenizer(prompts)\n",
    "\n",
    "        n_token = [len(tokens) for tokens in tokenized_prompts[\"input_ids\"]]\n",
    "        all_n_tokens.extend(n_token)\n",
    "    \n",
    "    \n",
    "    print(f\"cot={cot}: mean={np.mean(all_n_tokens):.2f}, min={np.min(all_n_tokens)}, max={np.max(all_n_tokens)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- That's why the paper assumes avg input token len = 1.5k. They do both direct prompt and CoT.\n",
    "- You don't want prompt cutoff. Max length is set to 2048 for now. Output max length set to 512 so the output CoT won't be cut off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
