{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from evaluation.template_list import template_list\n",
    "\n",
    "import utils\n",
    "from utils import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset_cutoff = 10\n",
    "# checkpoints = ['bigscience/T0_3B', 'bigscience/T0', 'bigscience/T0pp', 'google/flan-t5-xl', 'google/flan-t5-xxl']\n",
    "checkpoints = ['bigscience/T0']\n",
    "\n",
    "today = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "output_dir = f'./evaluation_result/{today}'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-14 00:48:58,301] [benchmark] [utils.py:25] loading model from bigscience/T0...\n",
      "[2023-01-14 00:49:32,081] [datasets.builder] [builder.py:785] Found cached dataset super_glue (/workspaces/seed/cache/hf_dataset/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n",
      "[2023-01-14 00:49:32,095] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-ddc6f475405b3d20.arrow\n",
      "[2023-01-14 00:49:32,561] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/rte - MNLI crowdsource: 0.8\n",
      "[2023-01-14 00:49:32,562] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/rte/MNLI crowdsource.json...\n",
      "[2023-01-14 00:49:32,575] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-ddc6f475405b3d20.arrow\n",
      "[2023-01-14 00:49:32,848] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/rte - guaranteed true: 0.6\n",
      "[2023-01-14 00:49:32,849] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/rte/guaranteed true.json...\n",
      "[2023-01-14 00:49:32,862] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-ddc6f475405b3d20.arrow\n",
      "[2023-01-14 00:49:33,134] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/rte - can we infer: 0.8\n",
      "[2023-01-14 00:49:33,134] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/rte/can we infer.json...\n",
      "[2023-01-14 00:49:33,146] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-ddc6f475405b3d20.arrow\n",
      "[2023-01-14 00:49:33,454] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/rte - GPT-3 style: 0.8\n",
      "[2023-01-14 00:49:33,455] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/rte/GPT-3 style.json...\n",
      "[2023-01-14 00:49:33,467] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-ddc6f475405b3d20.arrow\n",
      "[2023-01-14 00:49:33,739] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/rte - does this imply: 0.7\n",
      "[2023-01-14 00:49:33,739] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/rte/does this imply.json...\n",
      "[2023-01-14 00:49:33,751] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-ddc6f475405b3d20.arrow\n",
      "[2023-01-14 00:49:34,024] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/rte - should assume: 0.7\n",
      "[2023-01-14 00:49:34,024] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/rte/should assume.json...\n",
      "[2023-01-14 00:49:34,036] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-ddc6f475405b3d20.arrow\n",
      "[2023-01-14 00:49:34,306] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/rte - does it follow that: 0.7\n",
      "[2023-01-14 00:49:34,307] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/rte/does it follow that.json...\n",
      "[2023-01-14 00:49:34,319] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-ddc6f475405b3d20.arrow\n",
      "[2023-01-14 00:49:34,598] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/rte - based on the previous passage: 0.8\n",
      "[2023-01-14 00:49:34,598] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/rte/based on the previous passage.json...\n",
      "[2023-01-14 00:49:34,611] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-ddc6f475405b3d20.arrow\n",
      "[2023-01-14 00:49:34,882] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/rte - justified in saying: 0.6\n",
      "[2023-01-14 00:49:34,883] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/rte/justified in saying.json...\n",
      "[2023-01-14 00:49:34,895] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-ddc6f475405b3d20.arrow\n",
      "[2023-01-14 00:49:35,173] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/rte - must be true: 0.6\n",
      "[2023-01-14 00:49:35,173] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/rte/must be true.json...\n",
      "[2023-01-14 00:49:39,597] [datasets.builder] [builder.py:785] Found cached dataset super_glue (/workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n",
      "[2023-01-14 00:49:39,617] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:39,971] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - can we infer: 0.7\n",
      "[2023-01-14 00:49:39,971] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/can we infer.json...\n",
      "[2023-01-14 00:49:39,990] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:40,332] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - based on the previous passage: 0.8\n",
      "[2023-01-14 00:49:40,333] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/based on the previous passage.json...\n",
      "[2023-01-14 00:49:40,351] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:40,696] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - claim true/false/inconclusive: 0.8\n",
      "[2023-01-14 00:49:40,697] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/claim true_false_inconclusive.json...\n",
      "[2023-01-14 00:49:40,715] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:41,059] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - does it follow that: 0.7\n",
      "[2023-01-14 00:49:41,060] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/does it follow that.json...\n",
      "[2023-01-14 00:49:41,079] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:41,425] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - justified in saying: 0.7\n",
      "[2023-01-14 00:49:41,425] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/justified in saying.json...\n",
      "[2023-01-14 00:49:41,444] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:41,788] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - always/sometimes/never: 0.8\n",
      "[2023-01-14 00:49:41,789] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/always_sometimes_never.json...\n",
      "[2023-01-14 00:49:41,807] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:42,192] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - GPT-3 style: 0.7\n",
      "[2023-01-14 00:49:42,193] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/GPT-3 style.json...\n",
      "[2023-01-14 00:49:42,211] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:42,556] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - consider always/sometimes/never: 0.7\n",
      "[2023-01-14 00:49:42,556] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/consider always_sometimes_never.json...\n",
      "[2023-01-14 00:49:42,575] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:42,913] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - guaranteed true: 0.7\n",
      "[2023-01-14 00:49:42,914] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/guaranteed true.json...\n",
      "[2023-01-14 00:49:42,932] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:43,271] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - must be true: 0.8\n",
      "[2023-01-14 00:49:43,272] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/must be true.json...\n",
      "[2023-01-14 00:49:43,290] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:43,634] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - guaranteed/possible/impossible: 0.2\n",
      "[2023-01-14 00:49:43,635] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/guaranteed_possible_impossible.json...\n",
      "[2023-01-14 00:49:43,654] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:43,991] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - does this imply: 0.8\n",
      "[2023-01-14 00:49:43,992] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/does this imply.json...\n",
      "[2023-01-14 00:49:44,011] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:44,474] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - MNLI crowdsource: 0.8\n",
      "[2023-01-14 00:49:44,475] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/MNLI crowdsource.json...\n",
      "[2023-01-14 00:49:44,493] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:44,831] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - should assume: 0.7\n",
      "[2023-01-14 00:49:44,832] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/should assume.json...\n",
      "[2023-01-14 00:49:44,850] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/cb/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-a1eaaf6bd443be0c.arrow\n",
      "[2023-01-14 00:49:45,315] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/cb - take the following as truth: 0.7\n",
      "[2023-01-14 00:49:45,316] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/cb/take the following as truth.json...\n",
      "[2023-01-14 00:49:49,792] [datasets.builder] [builder.py:785] Found cached dataset anli (/workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b)\n",
      "[2023-01-14 00:49:49,811] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:50,166] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - MNLI crowdsource: 0.6\n",
      "[2023-01-14 00:49:50,167] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/MNLI crowdsource.json...\n",
      "[2023-01-14 00:49:50,188] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:50,534] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - should assume: 0.6\n",
      "[2023-01-14 00:49:50,535] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/should assume.json...\n",
      "[2023-01-14 00:49:50,553] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:50,888] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - does it follow that: 0.6\n",
      "[2023-01-14 00:49:50,889] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/does it follow that.json...\n",
      "[2023-01-14 00:49:50,907] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:51,284] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - GPT-3 style: 0.8\n",
      "[2023-01-14 00:49:51,284] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/GPT-3 style.json...\n",
      "[2023-01-14 00:49:51,302] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:51,644] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - based on the previous passage: 0.7\n",
      "[2023-01-14 00:49:51,645] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/based on the previous passage.json...\n",
      "[2023-01-14 00:49:51,663] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:52,002] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - justified in saying: 0.7\n",
      "[2023-01-14 00:49:52,002] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/justified in saying.json...\n",
      "[2023-01-14 00:49:52,020] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:52,405] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - take the following as truth: 0.6\n",
      "[2023-01-14 00:49:52,405] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/take the following as truth.json...\n",
      "[2023-01-14 00:49:52,423] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:52,766] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - must be true: 0.8\n",
      "[2023-01-14 00:49:52,766] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/must be true.json...\n",
      "[2023-01-14 00:49:52,785] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:53,126] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - can we infer: 0.7\n",
      "[2023-01-14 00:49:53,126] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/can we infer.json...\n",
      "[2023-01-14 00:49:53,144] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:53,493] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - guaranteed/possible/impossible: 0.3\n",
      "[2023-01-14 00:49:53,493] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/guaranteed_possible_impossible.json...\n",
      "[2023-01-14 00:49:53,511] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:53,880] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - always/sometimes/never: 0.4\n",
      "[2023-01-14 00:49:53,880] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/always_sometimes_never.json...\n",
      "[2023-01-14 00:49:53,898] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:54,238] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - does this imply: 0.7\n",
      "[2023-01-14 00:49:54,239] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/does this imply.json...\n",
      "[2023-01-14 00:49:54,257] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:54,645] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - consider always/sometimes/never: 0.2\n",
      "[2023-01-14 00:49:54,645] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/consider always_sometimes_never.json...\n",
      "[2023-01-14 00:49:54,663] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:55,012] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - claim true/false/inconclusive: 0.5\n",
      "[2023-01-14 00:49:55,012] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/claim true_false_inconclusive.json...\n",
      "[2023-01-14 00:49:55,030] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b/cache-dbd480aaa3b28ed4.arrow\n",
      "[2023-01-14 00:49:55,371] [benchmark] [3198601099.py:20] bigscience/T0: anli/None - guaranteed true: 0.7\n",
      "[2023-01-14 00:49:55,371] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/anli/None/guaranteed true.json...\n",
      "[2023-01-14 00:49:59,732] [datasets.builder] [builder.py:785] Found cached dataset super_glue (/workspaces/seed/cache/hf_dataset/super_glue/wsc.fixed/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n",
      "[2023-01-14 00:49:59,746] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wsc.fixed/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-641523664100ec2c.arrow\n",
      "[2023-01-14 00:49:59,990] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wsc.fixed - does the pronoun refer to: 0.7\n",
      "[2023-01-14 00:49:59,991] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wsc.fixed/does the pronoun refer to.json...\n",
      "[2023-01-14 00:50:00,004] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wsc.fixed/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-641523664100ec2c.arrow\n",
      "[2023-01-14 00:50:00,237] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wsc.fixed - by p they mean: 0.7\n",
      "[2023-01-14 00:50:00,237] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wsc.fixed/by p they mean.json...\n",
      "[2023-01-14 00:50:00,251] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wsc.fixed/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-641523664100ec2c.arrow\n",
      "[2023-01-14 00:50:00,558] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wsc.fixed - in other words: 0.8\n",
      "[2023-01-14 00:50:00,559] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wsc.fixed/in other words.json...\n",
      "[2023-01-14 00:50:00,572] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wsc.fixed/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-641523664100ec2c.arrow\n",
      "[2023-01-14 00:50:00,829] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wsc.fixed - I think they mean: 0.7\n",
      "[2023-01-14 00:50:00,829] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wsc.fixed/I think they mean.json...\n",
      "[2023-01-14 00:50:00,842] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wsc.fixed/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-641523664100ec2c.arrow\n",
      "[2023-01-14 00:50:01,044] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wsc.fixed - does p stand for: 0.8\n",
      "[2023-01-14 00:50:01,045] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wsc.fixed/does p stand for.json...\n",
      "[2023-01-14 00:50:01,058] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wsc.fixed/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-641523664100ec2c.arrow\n",
      "[2023-01-14 00:50:01,443] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wsc.fixed - GPT-3 Style: 0.1\n",
      "[2023-01-14 00:50:01,443] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wsc.fixed/GPT-3 Style.json...\n",
      "[2023-01-14 00:50:01,457] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wsc.fixed/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-641523664100ec2c.arrow\n",
      "[2023-01-14 00:50:01,688] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wsc.fixed - replaced with: 0.4\n",
      "[2023-01-14 00:50:01,688] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wsc.fixed/replaced with.json...\n",
      "[2023-01-14 00:50:01,701] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wsc.fixed/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-641523664100ec2c.arrow\n",
      "[2023-01-14 00:50:01,978] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wsc.fixed - p is/are r: 0.3\n",
      "[2023-01-14 00:50:01,979] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wsc.fixed/p is_are r.json...\n",
      "[2023-01-14 00:50:01,992] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wsc.fixed/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-641523664100ec2c.arrow\n",
      "[2023-01-14 00:50:02,259] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wsc.fixed - the pronoun refers to: 0.5\n",
      "[2023-01-14 00:50:02,260] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wsc.fixed/the pronoun refers to.json...\n",
      "[2023-01-14 00:50:02,273] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wsc.fixed/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-641523664100ec2c.arrow\n",
      "[2023-01-14 00:50:02,628] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wsc.fixed - Who or what is/are: 0.0\n",
      "[2023-01-14 00:50:02,628] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wsc.fixed/Who or what is_are.json...\n",
      "[2023-01-14 00:50:06,984] [datasets.builder] [builder.py:785] Found cached dataset winogrande (/workspaces/seed/cache/hf_dataset/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2)\n",
      "[2023-01-14 00:50:06,993] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2/cache-5aca6c830a1dfa33.arrow\n",
      "[2023-01-14 00:50:07,179] [benchmark] [3198601099.py:20] bigscience/T0: winogrande/winogrande_xl - does underscore refer to: 0.5\n",
      "[2023-01-14 00:50:07,180] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/winogrande/winogrande_xl/does underscore refer to.json...\n",
      "[2023-01-14 00:50:07,188] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2/cache-5aca6c830a1dfa33.arrow\n",
      "[2023-01-14 00:50:07,372] [benchmark] [3198601099.py:20] bigscience/T0: winogrande/winogrande_xl - stand for: 0.3\n",
      "[2023-01-14 00:50:07,372] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/winogrande/winogrande_xl/stand for.json...\n",
      "[2023-01-14 00:50:07,380] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2/cache-5aca6c830a1dfa33.arrow\n",
      "[2023-01-14 00:50:07,584] [benchmark] [3198601099.py:20] bigscience/T0: winogrande/winogrande_xl - underscore refer to: 0.7\n",
      "[2023-01-14 00:50:07,584] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/winogrande/winogrande_xl/underscore refer to.json...\n",
      "[2023-01-14 00:50:07,593] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2/cache-5aca6c830a1dfa33.arrow\n",
      "[2023-01-14 00:50:07,787] [benchmark] [3198601099.py:20] bigscience/T0: winogrande/winogrande_xl - fill in the blank: 0.4\n",
      "[2023-01-14 00:50:07,787] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/winogrande/winogrande_xl/fill in the blank.json...\n",
      "[2023-01-14 00:50:07,796] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2/cache-5aca6c830a1dfa33.arrow\n",
      "[2023-01-14 00:50:07,992] [benchmark] [3198601099.py:20] bigscience/T0: winogrande/winogrande_xl - Replace: 0.5\n",
      "[2023-01-14 00:50:07,993] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/winogrande/winogrande_xl/Replace.json...\n",
      "[2023-01-14 00:50:12,449] [datasets.builder] [builder.py:785] Found cached dataset super_glue (/workspaces/seed/cache/hf_dataset/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n",
      "[2023-01-14 00:50:12,464] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-163b382cdb37b2aa.arrow\n",
      "[2023-01-14 00:50:12,641] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wic - question-context-meaning-with-label: 0.4\n",
      "[2023-01-14 00:50:12,641] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wic/question-context-meaning-with-label.json...\n",
      "[2023-01-14 00:50:12,658] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-163b382cdb37b2aa.arrow\n",
      "[2023-01-14 00:50:12,822] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wic - question-context-meaning: 0.4\n",
      "[2023-01-14 00:50:12,822] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wic/question-context-meaning.json...\n",
      "[2023-01-14 00:50:12,835] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-163b382cdb37b2aa.arrow\n",
      "[2023-01-14 00:50:13,010] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wic - grammar_homework: 0.4\n",
      "[2023-01-14 00:50:13,011] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wic/grammar_homework.json...\n",
      "[2023-01-14 00:50:13,024] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-163b382cdb37b2aa.arrow\n",
      "[2023-01-14 00:50:13,234] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wic - affirmation_true_or_false: 0.5\n",
      "[2023-01-14 00:50:13,235] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wic/affirmation_true_or_false.json...\n",
      "[2023-01-14 00:50:13,248] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-163b382cdb37b2aa.arrow\n",
      "[2023-01-14 00:50:13,416] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wic - GPT-3-prompt: 0.4\n",
      "[2023-01-14 00:50:13,416] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wic/GPT-3-prompt.json...\n",
      "[2023-01-14 00:50:13,429] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-163b382cdb37b2aa.arrow\n",
      "[2023-01-14 00:50:13,603] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wic - same_sense: 0.5\n",
      "[2023-01-14 00:50:13,603] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wic/same_sense.json...\n",
      "[2023-01-14 00:50:13,616] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-163b382cdb37b2aa.arrow\n",
      "[2023-01-14 00:50:13,783] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wic - question-context: 0.4\n",
      "[2023-01-14 00:50:13,784] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wic/question-context.json...\n",
      "[2023-01-14 00:50:13,797] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-163b382cdb37b2aa.arrow\n",
      "[2023-01-14 00:50:13,964] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wic - GPT-3-prompt-with-label: 0.3\n",
      "[2023-01-14 00:50:13,965] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wic/GPT-3-prompt-with-label.json...\n",
      "[2023-01-14 00:50:13,978] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-163b382cdb37b2aa.arrow\n",
      "[2023-01-14 00:50:14,178] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wic - polysemous: 0.4\n",
      "[2023-01-14 00:50:14,178] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wic/polysemous.json...\n",
      "[2023-01-14 00:50:14,190] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-163b382cdb37b2aa.arrow\n",
      "[2023-01-14 00:50:14,544] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/wic - similar-sense: 0.0\n",
      "[2023-01-14 00:50:14,545] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/wic/similar-sense.json...\n",
      "[2023-01-14 00:50:18,910] [datasets.builder] [builder.py:785] Found cached dataset hellaswag (/workspaces/seed/cache/hf_dataset/hellaswag/default/0.1.0/c37cd37196278995f42bc32f532730ae9b0d5f0f4a2d3b97735c17ff3ad67169)\n",
      "[2023-01-14 00:50:18,926] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/hellaswag/default/0.1.0/c37cd37196278995f42bc32f532730ae9b0d5f0f4a2d3b97735c17ff3ad67169/cache-b15af1fd9af0be75.arrow\n",
      "[2023-01-14 00:50:19,910] [benchmark] [3198601099.py:20] bigscience/T0: hellaswag/None - Predict ending with hint: 0.0\n",
      "[2023-01-14 00:50:19,911] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/hellaswag/None/Predict ending with hint.json...\n",
      "[2023-01-14 00:50:19,927] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/hellaswag/default/0.1.0/c37cd37196278995f42bc32f532730ae9b0d5f0f4a2d3b97735c17ff3ad67169/cache-b15af1fd9af0be75.arrow\n",
      "[2023-01-14 00:50:21,333] [benchmark] [3198601099.py:20] bigscience/T0: hellaswag/None - Randomized prompts template: 0.0\n",
      "[2023-01-14 00:50:21,333] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/hellaswag/None/Randomized prompts template.json...\n",
      "[2023-01-14 00:50:21,348] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/hellaswag/default/0.1.0/c37cd37196278995f42bc32f532730ae9b0d5f0f4a2d3b97735c17ff3ad67169/cache-b15af1fd9af0be75.arrow\n",
      "[2023-01-14 00:50:22,837] [benchmark] [3198601099.py:20] bigscience/T0: hellaswag/None - complete_first_then: 0.0\n",
      "[2023-01-14 00:50:22,838] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/hellaswag/None/complete_first_then.json...\n",
      "[2023-01-14 00:50:22,853] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/hellaswag/default/0.1.0/c37cd37196278995f42bc32f532730ae9b0d5f0f4a2d3b97735c17ff3ad67169/cache-b15af1fd9af0be75.arrow\n",
      "[2023-01-14 00:50:24,607] [benchmark] [3198601099.py:20] bigscience/T0: hellaswag/None - if_begins_how_continues: 0.0\n",
      "[2023-01-14 00:50:24,608] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/hellaswag/None/if_begins_how_continues.json...\n",
      "[2023-01-14 00:50:28,974] [datasets.builder] [builder.py:785] Found cached dataset super_glue (/workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n",
      "[2023-01-14 00:50:28,990] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-f4bd523109c343ed.arrow\n",
      "[2023-01-14 00:50:29,384] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/copa - exercise: 0.9\n",
      "[2023-01-14 00:50:29,385] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/copa/exercise.json...\n",
      "[2023-01-14 00:50:29,399] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-f4bd523109c343ed.arrow\n",
      "[2023-01-14 00:50:29,404] [benchmark] [utils.py:102] Error when applying …What could happen next, C1 or C2? on {'premise': 'The man lost the competition.', 'choice1': 'The competition was sabotaged.', 'choice2': 'He intimidated his competitors.', 'question': 'cause', 'idx': 59, 'label': 0}\n",
      "[2023-01-14 00:50:29,405] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:29,408] [benchmark] [utils.py:102] Error when applying …What could happen next, C1 or C2? on {'premise': 'I regained composure from my fit of anger.', 'choice1': 'My heart pounded.', 'choice2': 'I took deep breaths.', 'question': 'cause', 'idx': 21, 'label': 1}\n",
      "[2023-01-14 00:50:29,408] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:29,411] [benchmark] [utils.py:102] Error when applying …What could happen next, C1 or C2? on {'premise': 'The woman lavished her friend with flattery.', 'choice1': 'She wanted to ask her friend for a favor.', 'choice2': \"She was irritated with her friend's whining.\", 'question': 'cause', 'idx': 56, 'label': 0}\n",
      "[2023-01-14 00:50:29,411] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:29,414] [benchmark] [utils.py:102] Error when applying …What could happen next, C1 or C2? on {'premise': \"The cook's eyes watered.\", 'choice1': 'He ran out of onions.', 'choice2': 'He cut an onion.', 'question': 'cause', 'idx': 18, 'label': 1}\n",
      "[2023-01-14 00:50:29,414] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:29,417] [benchmark] [utils.py:102] Error when applying …What could happen next, C1 or C2? on {'premise': 'The clock chimed.', 'choice1': 'It was the top of the hour.', 'choice2': 'The hour seemed to drag on.', 'question': 'cause', 'idx': 33, 'label': 0}\n",
      "[2023-01-14 00:50:29,417] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:29,420] [benchmark] [utils.py:102] Error when applying …What could happen next, C1 or C2? on {'premise': 'The pair of students came under scrutiny by the teacher.', 'choice1': 'The students both received excellent grades.', 'choice2': 'Their responses on the assignment were identical.', 'question': 'cause', 'idx': 42, 'label': 1}\n",
      "[2023-01-14 00:50:29,421] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:29,423] [benchmark] [utils.py:102] Error when applying …What could happen next, C1 or C2? on {'premise': 'My skin broke out into a rash.', 'choice1': 'I brushed against poison ivy in my yard.', 'choice2': 'I eradicated the poison ivy from my yard.', 'question': 'cause', 'idx': 50, 'label': 0}\n",
      "[2023-01-14 00:50:29,424] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:29,427] [benchmark] [utils.py:102] Error when applying …What could happen next, C1 or C2? on {'premise': \"The driver turned on the car's headlights.\", 'choice1': 'He heard thunder.', 'choice2': 'The sun went down.', 'question': 'cause', 'idx': 27, 'label': 1}\n",
      "[2023-01-14 00:50:29,427] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:29,430] [benchmark] [utils.py:102] Error when applying …What could happen next, C1 or C2? on {'premise': 'The man received a parking ticket.', 'choice1': 'He parallel parked on the street.', 'choice2': 'The parking meter expired.', 'question': 'cause', 'idx': 92, 'label': 1}\n",
      "[2023-01-14 00:50:29,430] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:29,556] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/copa - …What could happen next, C1 or C2?: 1.0\n",
      "[2023-01-14 00:50:29,556] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/copa/…What could happen next, C1 or C2?.json...\n",
      "[2023-01-14 00:50:29,571] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-f4bd523109c343ed.arrow\n",
      "[2023-01-14 00:50:29,970] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/copa - i_am_hesitating: 0.9\n",
      "[2023-01-14 00:50:29,970] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/copa/i_am_hesitating.json...\n",
      "[2023-01-14 00:50:29,986] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-f4bd523109c343ed.arrow\n",
      "[2023-01-14 00:50:30,377] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/copa - plausible_alternatives: 1.0\n",
      "[2023-01-14 00:50:30,378] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/copa/plausible_alternatives.json...\n",
      "[2023-01-14 00:50:30,393] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-f4bd523109c343ed.arrow\n",
      "[2023-01-14 00:50:30,789] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/copa - C1 or C2? premise, so/because…: 0.5\n",
      "[2023-01-14 00:50:30,789] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/copa/C1 or C2? premise, so_because….json...\n",
      "[2023-01-14 00:50:30,804] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-f4bd523109c343ed.arrow\n",
      "[2023-01-14 00:50:30,809] [benchmark] [utils.py:102] Error when applying …As a result, C1 or C2? on {'premise': 'The man lost the competition.', 'choice1': 'The competition was sabotaged.', 'choice2': 'He intimidated his competitors.', 'question': 'cause', 'idx': 59, 'label': 0}\n",
      "[2023-01-14 00:50:30,809] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:30,812] [benchmark] [utils.py:102] Error when applying …As a result, C1 or C2? on {'premise': 'I regained composure from my fit of anger.', 'choice1': 'My heart pounded.', 'choice2': 'I took deep breaths.', 'question': 'cause', 'idx': 21, 'label': 1}\n",
      "[2023-01-14 00:50:30,813] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:30,815] [benchmark] [utils.py:102] Error when applying …As a result, C1 or C2? on {'premise': 'The woman lavished her friend with flattery.', 'choice1': 'She wanted to ask her friend for a favor.', 'choice2': \"She was irritated with her friend's whining.\", 'question': 'cause', 'idx': 56, 'label': 0}\n",
      "[2023-01-14 00:50:30,816] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:30,819] [benchmark] [utils.py:102] Error when applying …As a result, C1 or C2? on {'premise': \"The cook's eyes watered.\", 'choice1': 'He ran out of onions.', 'choice2': 'He cut an onion.', 'question': 'cause', 'idx': 18, 'label': 1}\n",
      "[2023-01-14 00:50:30,819] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:30,822] [benchmark] [utils.py:102] Error when applying …As a result, C1 or C2? on {'premise': 'The clock chimed.', 'choice1': 'It was the top of the hour.', 'choice2': 'The hour seemed to drag on.', 'question': 'cause', 'idx': 33, 'label': 0}\n",
      "[2023-01-14 00:50:30,822] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:30,825] [benchmark] [utils.py:102] Error when applying …As a result, C1 or C2? on {'premise': 'The pair of students came under scrutiny by the teacher.', 'choice1': 'The students both received excellent grades.', 'choice2': 'Their responses on the assignment were identical.', 'question': 'cause', 'idx': 42, 'label': 1}\n",
      "[2023-01-14 00:50:30,825] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:30,828] [benchmark] [utils.py:102] Error when applying …As a result, C1 or C2? on {'premise': 'My skin broke out into a rash.', 'choice1': 'I brushed against poison ivy in my yard.', 'choice2': 'I eradicated the poison ivy from my yard.', 'question': 'cause', 'idx': 50, 'label': 0}\n",
      "[2023-01-14 00:50:30,829] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:30,832] [benchmark] [utils.py:102] Error when applying …As a result, C1 or C2? on {'premise': \"The driver turned on the car's headlights.\", 'choice1': 'He heard thunder.', 'choice2': 'The sun went down.', 'question': 'cause', 'idx': 27, 'label': 1}\n",
      "[2023-01-14 00:50:30,832] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:30,835] [benchmark] [utils.py:102] Error when applying …As a result, C1 or C2? on {'premise': 'The man received a parking ticket.', 'choice1': 'He parallel parked on the street.', 'choice2': 'The parking meter expired.', 'question': 'cause', 'idx': 92, 'label': 1}\n",
      "[2023-01-14 00:50:30,835] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:30,960] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/copa - …As a result, C1 or C2?: 1.0\n",
      "[2023-01-14 00:50:30,960] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/copa/…As a result, C1 or C2?.json...\n",
      "[2023-01-14 00:50:30,975] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-f4bd523109c343ed.arrow\n",
      "[2023-01-14 00:50:31,369] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/copa - best_option: 0.5\n",
      "[2023-01-14 00:50:31,370] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/copa/best_option.json...\n",
      "[2023-01-14 00:50:31,385] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-f4bd523109c343ed.arrow\n",
      "[2023-01-14 00:50:31,411] [benchmark] [utils.py:102] Error when applying …which may be caused by on {'premise': 'The tree branch landed in the river.', 'choice1': 'The branch moved downstream.', 'choice2': \"The river's current became stronger.\", 'question': 'effect', 'idx': 71, 'label': 0}\n",
      "[2023-01-14 00:50:31,412] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:31,760] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/copa - …which may be caused by: 0.5555555555555556\n",
      "[2023-01-14 00:50:31,761] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/copa/…which may be caused by.json...\n",
      "[2023-01-14 00:50:31,775] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-f4bd523109c343ed.arrow\n",
      "[2023-01-14 00:50:32,170] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/copa - more likely: 0.9\n",
      "[2023-01-14 00:50:32,170] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/copa/more likely.json...\n",
      "[2023-01-14 00:50:32,186] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-f4bd523109c343ed.arrow\n",
      "[2023-01-14 00:50:32,564] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/copa - cause_effect: 0.8\n",
      "[2023-01-14 00:50:32,564] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/copa/cause_effect.json...\n",
      "[2023-01-14 00:50:32,579] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-f4bd523109c343ed.arrow\n",
      "[2023-01-14 00:50:32,606] [benchmark] [utils.py:102] Error when applying …why? C1 or C2 on {'premise': 'The tree branch landed in the river.', 'choice1': 'The branch moved downstream.', 'choice2': \"The river's current became stronger.\", 'question': 'effect', 'idx': 71, 'label': 0}\n",
      "[2023-01-14 00:50:32,606] [benchmark] [utils.py:103] not enough values to unpack (expected 2, got 1)\n",
      "[2023-01-14 00:50:32,954] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/copa - …why? C1 or C2: 0.5555555555555556\n",
      "[2023-01-14 00:50:32,955] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/copa/…why? C1 or C2.json...\n",
      "[2023-01-14 00:50:32,970] [datasets.arrow_dataset] [arrow_dataset.py:3930] Loading cached shuffled indices for dataset at /workspaces/seed/cache/hf_dataset/super_glue/copa/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-f4bd523109c343ed.arrow\n",
      "[2023-01-14 00:50:33,348] [benchmark] [3198601099.py:20] bigscience/T0: super_glue/copa - choose: 1.0\n",
      "[2023-01-14 00:50:33,349] [benchmark] [utils.py:187] dumping failed cases to ./evaluation_result/20230114/T0/super_glue/copa/choose.json...\n",
      "[2023-01-14 00:50:33,352] [benchmark] [utils.py:165] dumping results to ./evaluation_result/20230114/T0/T0.csv...\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in checkpoints:\n",
    "    t2t = utils.build_t2t(checkpoint)\n",
    "    results = []\n",
    "\n",
    "    for (dataset_name, subset_name), prompts in template_list.items():\n",
    "        raw_dataset = utils.load_raw_dataset(dataset_name, subset_name)\n",
    "\n",
    "        for prompt_name in prompts:\n",
    "            prompt = utils.get_prompt(dataset_name, subset_name, prompt_name)\n",
    "\n",
    "            input_text, target_text = utils.preprocess_dataset(\n",
    "                raw_dataset, prompt, cutoff=dataset_cutoff\n",
    "            )\n",
    "            test_size = len(input_text)\n",
    "\n",
    "            accuracy, t_lapse, failed_cases = utils.eval(\n",
    "                t2t, input_text, target_text, batch_size=batch_size\n",
    "            )\n",
    "\n",
    "            logger.info(\n",
    "                f\"{checkpoint}: {dataset_name}/{subset_name} - {prompt_name}: {accuracy}\"\n",
    "            )\n",
    "\n",
    "            result = utils.Result(\n",
    "                checkpoint,\n",
    "                dataset_name,\n",
    "                subset_name,\n",
    "                test_size,\n",
    "                t_lapse,\n",
    "                prompt_name,\n",
    "                accuracy,\n",
    "            )\n",
    "            results.append(result)\n",
    "\n",
    "            utils.dump_failed_cases_as_json(\n",
    "                failed_cases,\n",
    "                checkpoint,\n",
    "                dataset_name,\n",
    "                subset_name,\n",
    "                prompt_name,\n",
    "                output_dir,\n",
    "            )\n",
    "\n",
    "    utils.dump_result_as_csv(results, checkpoint, output_dir)\n",
    "\n",
    "    del t2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
